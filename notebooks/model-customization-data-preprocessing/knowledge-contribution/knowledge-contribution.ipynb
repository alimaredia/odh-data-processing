{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b320d737-0c9c-4023-8959-d4f816b5deac",
   "metadata": {},
   "source": [
    "# Knowledge Contribution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44999da4-6541-4076-8d1e-a53536fee292",
   "metadata": {},
   "source": [
    "## Knowledge Contribution Overview\n",
    "\n",
    "To add knowledge to a model, a user will group source documents of that contain the knowledge into knowledge contributions. A knowledge contribution is made up of:\n",
    "\n",
    "1. Chunks of one or more documents.\n",
    "2. A one sentence contribution summary that describes the documents.\n",
    "3. A few word contribution domain that describes the field of the documents.\n",
    "4. 5 or more seed examples from the documents.\n",
    "\n",
    "The contribution summary, domain, and seed examples for a contribution are written to a YAML file. In this notebook we will create a that YAML file will be called `qna.yaml`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b456c1d-546f-4be3-876e-ce05c381fb22",
   "metadata": {},
   "source": [
    "## Initializing a Knowledge Contribution\n",
    "\n",
    "To get started we need to pick the documents that will be used for our contribution.\n",
    "\n",
    "There are documents in `sample-contributions/sample-pdfs` that can be grouped into a `nfl` contribution: `2022-nfl-rulebook.pdf` and `2023-nfl-rulebook.pdf`.\n",
    "\n",
    "Chunks of the two documents live in `sample-contributions/nfl/chunks.jsonl`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0791c606-9a91-4476-804b-e3e8db10f46e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "WORKSPACE_DIR = Path(\"sample-contributions\")\n",
    "contribution_name = \"nfl\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a925a82-53b4-4b21-b61a-66846b4bdf27",
   "metadata": {},
   "source": [
    "## Knowledge Contribution Summary\n",
    "\n",
    "The chunks as well as the contribution information are the inputs to generating synthetic data. This generated data is used to create a dataset for fine-tuning the model on the contribution.\n",
    "When generating synthetic data, a model (known as the teacher model) generates data based on the source document.\n",
    "The contribution summary and domain are used in the prompts that are sent to the teacher model to create data.\n",
    "\n",
    "The document gets broken up into chunks, and each chunk is in the prompt sent to the teacher model.\n",
    "The contribution summary provides additional context to each chunk of a source document ensuring the teacher model has necessary background information.\n",
    "\n",
    "Contribution summaries should be specific, avoid acronyms or other vague references, and the represent the documents focus areas.\n",
    "When a contribution includes many versions of the same document, publication dates, volume numbers, or any other identifiers to distinguish between versions should be included in the contribution summary.\n",
    "\n",
    "Here is an example of a contribution summary from a recent paper on [inference-time scaling](https://arxiv.org/pdf/2502.01618):\n",
    "\n",
    "`A Probabilistic Inference Approach to Inference-Time Scaling of Large Language Models (LLMs)`\n",
    "\n",
    "Since the title of the paper does a good job summaraizing the paper, the summary is based off the title but with the acronym LLM spelled out. \n",
    "\n",
    "Usually contributions only have one document. Contributions with multiple documents happen when the subject matter and format are similar among a group of documents. \n",
    "\n",
    "An example of a contribution having multiple documents would be the desire to teach a model an organization's bylaws over the years 2021, 2022, 2023, 2024, with a different PDF for each year.\n",
    "\n",
    "A contribution summary in this case might look like:\n",
    "\n",
    "`Bylaws of organization Foo from 2021 - 2024`\n",
    "\n",
    "In the case that there was only one source document from the year 2023, the contribution summary would be:\n",
    "\n",
    "`2023 Bylaws of organization Foo`\n",
    "\n",
    "Another example of having multiple documents within the same contribution would be if the documents had the same format. An example here could be grouping together a furniture company's instruction manuals. The format and layout of the instruction manuals would be the same across different pieces of furniture, but each manual covers different furniture.\n",
    "\n",
    "`Furniture company Foo's assembly instructions for tables, desks, and nightstands`\n",
    "\n",
    "If the contribution only contained a PDF for the assembly instructions for an oak dining table the summary would be:\n",
    "\n",
    "`Assembly instructions for furniture company Foo's oak dining table`\n",
    "\n",
    "Based on this overview let's set the contribution summary of a `nfl` contribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e25b90e0-aca4-4884-b296-91ae8f27fe95",
   "metadata": {},
   "outputs": [],
   "source": [
    "contribution_summary = \"Official playing rules of the National Football League 2022, 2023\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4141abe-98fc-4d46-b096-e816d78867f8",
   "metadata": {},
   "source": [
    "## Knowledge Contribution Domain\n",
    "\n",
    "A contribution's domain is the overarching subject or scope of the source document(s). The domain provides critical context to guide the teacher model in generating synthetic data that is relevant and grounded.\n",
    "\n",
    "The domain is brief and should not exceed 3 words, but should ideally be 1-2 words.\n",
    "\n",
    "To determine the domain, users should review document's primary subject and identify the main topic or purpose of the document.\n",
    "Consider the intended use of the document and align it with the use case or audience. E.g. a tech manual for developers might fall under the “software development” domain.\n",
    "\n",
    "For the contribution summary examples discussed in the previous sections, domains could be `Artificial Intelligence Research`, `Bylaws`, and `Furniture Assembly`.\n",
    "\n",
    "**Note:** Different contributions can have the same domain\n",
    "\n",
    "Here is the contribution domain for the `nfl` contribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "882dd4e8-c319-43f2-a071-fef1d1e8215d",
   "metadata": {},
   "outputs": [],
   "source": [
    "contribution_domain = \"Sports Rules\" "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffa3266f-ffc9-4a98-af23-cac903bcf14f",
   "metadata": {},
   "source": [
    "## Knowledge Contribution Seed Examples\n",
    "\n",
    "Each knowledge contribution should have at least 5 seed examples. A seed example consists of a `context` and 3 `question` and `answer` pairs. These questions and answers would be typical in the style of questions the user of the model would ask and typical in style of the answer the user of the trained model would like to receive.\n",
    "\n",
    "### Contexts\n",
    "\n",
    "A context is a part of the source document that is no more than 500 tokens. The contexts should be varied by text type. During synthetic data generation this is to guide the teacher model in handling varied text types present in the source documents.\n",
    "\n",
    "For example if you have a document with paragraphs of text, bulleted lists, and tables, there should be a context for each type.\n",
    "\n",
    "After chunking a document, using different kinds of chunks as a contexts is a simple way to get contexts for seed examples.\n",
    "\n",
    "Below is a chunk from the nfl rules documents that can be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cfb9293e-e3bb-4b56-8788-a89ec515530c",
   "metadata": {},
   "outputs": [],
   "source": [
    "context_1 = \"\"\"\n",
    "A.R. 15.260 Line to gain on fourth down. Fourth-and-2 on B41. \n",
    "With 3:43 remaining in the fourth quarter, back A2 takes a handoff and runs to the B39 where he is hit and driven backward.\n",
    "The officials spot the ball at the B39 and award possession to Team B.\n",
    "Ruling: Reviewable. A's ball first-and-10 on B39, and wind on the ready.\n",
    "Team A coach must challenge this play outside two minutes of either half.\n",
    "Replay Official is not responsible for initiating a review for a turnover on downs for plays that start before the two-minute warning.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97912d3f-cd8e-4683-916a-37eecabbe6ce",
   "metadata": {},
   "source": [
    "### Selecting chunks for contexts\n",
    "\n",
    "Various methods can be used to find diverse chunks from a set of chunks to use as contexts. The below code gets a user started by randomly selects a preset number of chunks and returns them for the next step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d4b16c74-a50d-46bf-92d2-917e6165f8f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A.R. 15.266 UNR/UNS enforcement\n",
      "First-and-10 on A30. QBA1 throws a low pass that is ruled intercepted by B2 at the A43-yard line. B2 returns the ball to the A10yard line where he is tackled by the facemask by A3. Replays show that the ball hit the ground before B2 intercepted it.\n",
      "Ruling: Reviewable. A's ball second-and-25 on A15, reset the clock to the time when the ball hit the ground. Pass is incomplete but the facemask penalty must be enforced. This applies to any UNR or UNS foul, and it is enforced as a dead ball penalty. Only the Replay Official can initiate a review of this play.\n"
     ]
    }
   ],
   "source": [
    "from utils import get_random_chunks\n",
    "\n",
    "chunks_jsonl_path = WORKSPACE_DIR / contribution_name / \"chunks.jsonl\"\n",
    "\n",
    "random_chunks = get_random_chunks(chunks_jsonl_path, num_chunks=4)\n",
    "print(random_chunks[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70c78a21-a073-488a-9257-f7f37ac42a59",
   "metadata": {},
   "source": [
    "### Question and Answer Pairs\n",
    "\n",
    "Each context must have 3 question and answer pairs. The purpose of these question and answer pairs is to demonstrate to the teacher model the style and structure of questions and answers to generate for the given text type. \n",
    "\n",
    "The questions and the answers must be grounded in the context. Answers should be detailed as opposed to short. Single word answers should be avoided. This is because detailed answers set the tone for the teacher model to generate comprehensive responses during synthetic data generation. Detailed answers also cover more information from the context as well.\n",
    "\n",
    "Here is a context and 3 question and answer pairs for the `nfl` documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e7488534-c021-47fc-97e8-ecb0216e4130",
   "metadata": {},
   "outputs": [],
   "source": [
    "nfl_qna1 = [\n",
    "    {\n",
    "        \"question\": \"What is the distance Team A needs to gain on fourth down?\",\n",
    "        \"answer\": \"Team A needs to gain 2 yards on fourth down.\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \" What is the final spot of the ball and the team that is awarded possession after the play?\",\n",
    "        \"answer\": \"The ball is spotted at the B39 and Team B is awarded possession.\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"Why might the Team A coach choose to challenge the play?\",\n",
    "        \"answer\": \" The coach might choose to challenge the play because it results in a turnover on downs, which is reviewable, and the replay official will not initiate a review for such plays that start before the two-minute warning.\"\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88a4260a-30f8-4fdc-9594-78995cd7f5e5",
   "metadata": {},
   "source": [
    "### Autogenerating Question and Answer Pairs\n",
    "\n",
    "Contexts can be used to generate question and answer pairs. Here we are using 4 more contexts and setting a  sending them to an LLM served on an OpenAI compatible endpoint. First we need to ensure the `openai` library is installed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "50ee1779-9ae4-49d5-8c88-5037bf2dec15",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -qq openai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "478b4fa0-01f0-4f55-a82e-848cddb2c901",
   "metadata": {},
   "source": [
    "Next we need to set the url, key and model name for the OpenAI compatible endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1b1c8301-2ba1-45b9-b8c1-1016a167f620",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "API_KEY = os.getenv(\"MODEL_API_KEY\") or \"\"  # the API access key for your account (cannot be empty)\n",
    "ENDPOINT_URL = os.getenv(\"MODEL_ENDPOINT_URL\") or \"\" # the URL of your model's API. URL can end in \"/v1\"\n",
    "MODEL_NAME = os.getenv(\"MODEL_NAME\") or \"\" # the name of your model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbd0f978-e022-4e1d-b3cc-ddf778430d03",
   "metadata": {},
   "source": [
    "Finally we need to set the prompt used to generate the questions and answer pairs. The simple prompt provided should be used as a starting point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0116d012-48da-422b-9518-79261b5ced73",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import generate_qa_pairs\n",
    "\n",
    "qa_gen_prompt = \"\"\"\n",
    "Read the following paragraph and generate exactly 3 question-answer pairs.\n",
    "Format your response as a JSON list of objects, each with 'question' and 'answer'.\n",
    "\"\"\"\n",
    "seed_examples = [{\"context\": context_1, \"questions_and_answers\": nfl_qna1}]\n",
    "\n",
    "for chunk in random_chunks:\n",
    "    # TODO:\n",
    "    # 1. ensure what is returned by generate_qa_pairs is a dict with the key \"questions_and_answers\"\n",
    "    # 2. pretty print context + question and answer pairs for users to view\n",
    "    qa_pairs = generate_qa_pairs(qa_gen_prompt, chunk, API_KEY, ENDPOINT_URL, MODEL_NAME)\n",
    "    seed_examples.append({\"context\": chunk, \"questions_and_answers\": qa_pairs.get(\"questions_and_answers\")})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f0825b7-50e9-4d10-8856-3abcb2d65066",
   "metadata": {},
   "source": [
    "### Creating the YAML file\n",
    "\n",
    "Now we will add all of the contribution information together to create a yaml file called qna.yaml with all of the seed examples. This is needed to create the seed_data input for SDG-Hub. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "82c4325a-2e10-46f0-9e7a-655ba05e72fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import create_knowledge_qna_yaml\n",
    "\n",
    "qna_yaml_path = create_knowledge_qna_yaml(WORKSPACE_DIR / contribution_name, contribution_domain, contribution_summary, seed_examples)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03ec1275-2f1a-4625-8d58-b8f685c3ccc0",
   "metadata": {},
   "source": [
    "The `qna.yaml` files can be quickly reviewed to ensure they includes the required elements and correct number of each. It is recommended to have at least 5 seed examples. Each seed example must have 3 question and answer pairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "276fb3dc-5d34-4441-8046-1af9d4cd605d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample-contributions/nfl/qna.yaml\n",
      "Reviewing seed examples file at /Users/amaredia/dev/odh-data-processing/notebooks/model-customization-data-preprocessing/knowledge-contribution/sample-contributions/nfl/qna.yaml\n",
      "Found contribution summary...\n",
      "Found 'domain'...\n",
      "Found 5 'contexts' in 'seed_examples'. Minimum expected number is 5...\n",
      "Seed Example 1 contains expected number (3) of 'question_and_answers'...\n",
      "Seed Example 2 contains expected number (3) of 'question_and_answers'...\n",
      "Seed Example 3 contains expected number (3) of 'question_and_answers'...\n",
      "Seed Example 4 contains expected number (3) of 'question_and_answers'...\n",
      "Seed Example 5 contains expected number (3) of 'question_and_answers'...\n",
      "Seed Examples YAML /Users/amaredia/dev/odh-data-processing/notebooks/model-customization-data-preprocessing/knowledge-contribution/sample-contributions/nfl/qna.yaml is valid :)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from utils import review_seed_examples_file\n",
    "\n",
    "print(qna_yaml_path)\n",
    "qna_yaml_path = Path(\"sample-contributions/nfl/qna.yaml\")\n",
    "review_seed_examples_file(qna_yaml_path, min_seed_examples=5, num_qa_pairs=3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
